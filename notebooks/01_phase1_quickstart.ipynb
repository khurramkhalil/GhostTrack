{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 Quick Start: GhostTrack Infrastructure\n",
    "\n",
    "This notebook demonstrates how to use all Phase 1 components:\n",
    "1. Configuration loading\n",
    "2. Data loading (TruthfulQA)\n",
    "3. GPT-2 model wrapper with hooks\n",
    "4. JumpReLU SAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import load_config\n",
    "\n",
    "# Load configuration from .claude file\n",
    "config = load_config()\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Base model: {config.model.base_model}\")\n",
    "print(f\"  d_model: {config.model.d_model}\")\n",
    "print(f\"  n_layers: {config.model.n_layers}\")\n",
    "\n",
    "print(\"\\nSAE Configuration:\")\n",
    "print(f\"  Architecture: {config.sae.architecture}\")\n",
    "print(f\"  d_hidden: {config.sae.d_hidden}\")\n",
    "print(f\"  Threshold: {config.sae.threshold}\")\n",
    "print(f\"  Lambda sparse: {config.sae.lambda_sparse}\")\n",
    "\n",
    "print(\"\\nTracking Configuration:\")\n",
    "print(f\"  Top-k features: {config.tracking.top_k_features}\")\n",
    "print(f\"  Semantic weight: {config.tracking.semantic_weight}\")\n",
    "print(f\"  Association threshold: {config.tracking.association_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading (TruthfulQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_truthfulqa\n",
    "\n",
    "print(\"Loading TruthfulQA dataset...\")\n",
    "print(\"Note: First load may take a few minutes to download from HuggingFace\\n\")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_truthfulqa(\n",
    "    cache_dir='../data/cache',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "print(f\"Total: {len(train_dataset) + len(val_dataset) + len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a sample example\n",
    "example = train_dataset[0]\n",
    "\n",
    "print(\"Example Question-Answer Pair:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ID: {example.id}\")\n",
    "print(f\"Category: {example.category}\")\n",
    "print(f\"\\nQuestion: {example.prompt}\")\n",
    "print(f\"\\nFactual Answer: {example.factual_answer}\")\n",
    "print(f\"\\nHallucinated Answer: {example.hallucinated_answer}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze category distribution\n",
    "categories = train_dataset.get_categories()\n",
    "category_counts = train_dataset.get_category_counts()\n",
    "\n",
    "print(f\"Number of categories: {len(categories)}\")\n",
    "print(f\"\\nTop 10 categories by count:\")\n",
    "sorted_cats = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for cat, count in sorted_cats:\n",
    "    print(f\"  {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPT-2 Model Wrapper with Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPT2WithResidualHooks\n",
    "\n",
    "print(\"Loading GPT-2 model with hooks...\")\n",
    "model = GPT2WithResidualHooks(\n",
    "    model_name='gpt2',\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(f\"Device: {model.device}\")\n",
    "print(f\"Number of layers: {model.n_layers}\")\n",
    "print(f\"Hidden dimension: {model.d_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process some text\n",
    "test_text = \"The capital of France is Paris.\"\n",
    "\n",
    "print(f\"Processing text: '{test_text}'\\n\")\n",
    "outputs = model.process_text(test_text)\n",
    "\n",
    "print(\"Output keys:\", outputs.keys())\n",
    "print(f\"\\nLogits shape: {outputs['logits'].shape}\")\n",
    "print(f\"Number of residual stream activations: {len(outputs['residual_stream'])}\")\n",
    "print(f\"Number of MLP activations: {len(outputs['mlp_outputs'])}\")\n",
    "print(f\"Number of attention activations: {len(outputs['attn_outputs'])}\")\n",
    "\n",
    "print(f\"\\nResidual stream shape per layer: {outputs['residual_stream'][0].shape}\")\n",
    "print(f\"Format: [batch_size, seq_length, hidden_dim]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activation magnitudes across layers\n",
    "layer_norms = []\n",
    "for i, residual in enumerate(outputs['residual_stream']):\n",
    "    norm = torch.norm(residual, dim=-1).mean().item()\n",
    "    layer_norms.append(norm)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(12), layer_norms, marker='o')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Average Activation Norm')\n",
    "plt.title('Residual Stream Activation Norms Across Layers')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. JumpReLU SAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import JumpReLUSAE\n",
    "\n",
    "# Create SAE\n",
    "sae = JumpReLUSAE(\n",
    "    d_model=768,\n",
    "    d_hidden=4096,\n",
    "    threshold=0.1,\n",
    "    lambda_sparse=0.01\n",
    ")\n",
    "\n",
    "print(f\"SAE created with:\")\n",
    "print(f\"  Input dim: {sae.d_model}\")\n",
    "print(f\"  Hidden dim: {sae.d_hidden}\")\n",
    "print(f\"  Threshold: {sae.threshold.item():.3f}\")\n",
    "print(f\"  Total parameters: {sae.get_num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SAE on actual model activations\n",
    "# Use layer 6 (middle layer)\n",
    "layer_6_activations = outputs['residual_stream'][6]\n",
    "\n",
    "print(f\"Input shape: {layer_6_activations.shape}\")\n",
    "\n",
    "# Forward pass through SAE\n",
    "sae_output = sae.forward(layer_6_activations)\n",
    "\n",
    "print(f\"\\nSAE Output:\")\n",
    "print(f\"  Reconstruction shape: {sae_output['reconstruction'].shape}\")\n",
    "print(f\"  Features shape: {sae_output['features'].shape}\")\n",
    "print(f\"  Error shape: {sae_output['error'].shape}\")\n",
    "print(f\"  Sparsity: {sae_output['sparsity'].item():.4f}\")\n",
    "print(f\"  Active features per token: {sae.count_active_features(layer_6_activations):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction loss\n",
    "loss_dict = sae.loss(layer_6_activations, return_components=True)\n",
    "\n",
    "print(\"Loss Components:\")\n",
    "print(f\"  Total loss: {loss_dict['total_loss'].item():.6f}\")\n",
    "print(f\"  Reconstruction loss: {loss_dict['recon_loss'].item():.6f}\")\n",
    "print(f\"  Sparsity loss: {loss_dict['sparsity_loss'].item():.6f}\")\n",
    "print(f\"  Sparsity: {loss_dict['sparsity'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sparse activation pattern\n",
    "features = sae_output['features'][0].detach().cpu().numpy()  # [seq_len, 4096]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(features.T, aspect='auto', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Activation')\n",
    "plt.xlabel('Token Position')\n",
    "plt.ylabel('Feature ID')\n",
    "plt.title('SAE Feature Activations (Sparse)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "active_per_token = (features > 0).sum(axis=1)\n",
    "plt.bar(range(len(active_per_token)), active_per_token)\n",
    "plt.xlabel('Token Position')\n",
    "plt.ylabel('Number of Active Features')\n",
    "plt.title('Active Features per Token')\n",
    "plt.axhline(y=active_per_token.mean(), color='r', linestyle='--', \n",
    "            label=f'Mean: {active_per_token.mean():.1f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JumpReLU activation function directly\n",
    "test_values = torch.tensor([[-0.5, -0.2, 0.0, 0.05, 0.1, 0.2, 0.5, 1.0]])\n",
    "activated = sae.jumprelu(test_values)\n",
    "\n",
    "print(\"JumpReLU Activation Test:\")\n",
    "print(f\"Threshold: {sae.threshold.item():.3f}\")\n",
    "print(f\"\\nInput:  {test_values[0].tolist()}\")\n",
    "print(f\"Output: {activated[0].tolist()}\")\n",
    "print(f\"\\nNote: Values > {sae.threshold.item():.3f} are preserved, others set to 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combining Components: Full Pipeline Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a factual vs hallucinated pair\n",
    "example = test_dataset[5]  # Pick an example\n",
    "\n",
    "print(\"Question:\", example.prompt)\n",
    "print(\"\\nFactual Answer:\", example.factual_answer)\n",
    "print(\"Hallucinated Answer:\", example.hallucinated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process both through model\n",
    "factual_outputs = model.process_text(example.prompt + \" \" + example.factual_answer)\n",
    "halluc_outputs = model.process_text(example.prompt + \" \" + example.hallucinated_answer)\n",
    "\n",
    "print(\"Processed both answers through GPT-2\")\n",
    "print(f\"Factual seq length: {factual_outputs['logits'].shape[1]}\")\n",
    "print(f\"Halluc seq length: {halluc_outputs['logits'].shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass through SAE (layer 8 as example)\n",
    "factual_layer8 = factual_outputs['residual_stream'][8]\n",
    "halluc_layer8 = halluc_outputs['residual_stream'][8]\n",
    "\n",
    "factual_sae = sae.forward(factual_layer8)\n",
    "halluc_sae = sae.forward(halluc_layer8)\n",
    "\n",
    "print(\"\\nSAE Analysis:\")\n",
    "print(f\"Factual sparsity: {factual_sae['sparsity'].item():.4f}\")\n",
    "print(f\"Halluc sparsity: {halluc_sae['sparsity'].item():.4f}\")\n",
    "\n",
    "factual_active = sae.count_active_features(factual_layer8)\n",
    "halluc_active = sae.count_active_features(halluc_layer8)\n",
    "\n",
    "print(f\"\\nFactual active features: {factual_active:.1f}\")\n",
    "print(f\"Halluc active features: {halluc_active:.1f}\")\n",
    "print(f\"Difference: {abs(factual_active - halluc_active):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Phase 1 Infrastructure is complete! You've seen:\n",
    "\n",
    "1. ✅ **Configuration system** - Load settings from YAML\n",
    "2. ✅ **Data loading** - TruthfulQA with train/val/test splits\n",
    "3. ✅ **Model wrapper** - Extract activations from GPT-2\n",
    "4. ✅ **SAE model** - Sparse feature extraction with JumpReLU\n",
    "\n",
    "### Next Steps (Phase 2):\n",
    "- Train SAEs on Wikipedia corpus\n",
    "- Achieve reconstruction loss < 0.01\n",
    "- Interpret learned features\n",
    "- Build hypothesis tracking system\n",
    "\n",
    "### Questions?\n",
    "See `PHASE1_SUMMARY.md` for detailed documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
